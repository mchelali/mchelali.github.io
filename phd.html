<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="../../../../favicon.ico">

    <title>Mohamed Chelali</title>

    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/jumbotron.css" rel="stylesheet">
    <!--link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"-->


      <link rel="stylesheet" href="css/style.css">

    <!-- include font awosome package -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">


  </head>

  <body>

      
    <div class="container" >

        <h1 class="display-4">Prise en compte de l'information spatiale et temporelle pour l'analyse de séquences d'images </h1>

        <h3>Thèse en informatique, spécialité analyse et traitement d'image</h3>

        <hr>
        <center>
            <h4>La soutenance se déroulera le <b>vendredi 26 Novembre 2021, à 14h,</b> à l’Université de Paris, 45 rue des Saints-Pères, Paris.
                (Métro : Saints Germains des Près) 
                </h4>
        </center>
        <hr>

     
        <h1 class="display-5">Résumé </h1>

        L'évolution de la technologie numérique a permis la multiplicité des capteurs d'images avec lesquels des masses de données visuelles sont quotidiennement produites. 
        Dans certains contextes, ces données peuvent prendre la forme de séquences temporelles d'images $2D$ conduisant à des données $3D$ que nous noterons $2D+t$. 
        Ce type de données est fréquent dans plusieurs domaines tels que la télésurveillance ou la télédétection. 
        De par leur dimension, l'analyse et l'interprétation de toute cette masse de données constitue un des défis importants en vision par ordinateur. 
        Cette thèse s'inscrit dans le contexte de l'exploitation de ces données afin de pouvoir les classifier, en exploitant au maximum la richesse des informations spatiales et temporelles portées par ces données.  
        Les travaux de recherche présentés dans ce manuscrit comprennent deux méthodes qui procèdent différemment mais dont le point commun repose sur un changement de représentation des données initiales. 
        La première méthode se base sur l'extraction de caractéristiques expertes  (<i>hand-crafted</i>) tandis que la deuxième concerne l'utilisation des méthodes d'apprentissage automatique, en particulier les réseaux de neurones convolutifs profonds. 
        À travers ces deux méthodes, nous nous proposons d'étudier la stabilité temporelle des séquences temporelles d'images avec les caractéristiques expertes et étudier leurs variabilités spatiale et temporelle avec les réseaux de neurones convolutifs profonds.  
        Les deux méthodes sont ensuite évaluées sur deux applications différentes. 
        Une de ses application concerne les séries temporelles d'images satellitaires et l'autre concerne les vidéos de caméra de surveillance. 
        Les résultats expérimentaux illustrent l’intérêt des méthodes proposées. 
        
        
        

        <h1 class="display-5">Abstract </h1>
        
        
        The evolution of digital technology has allowed the multiplicity of image sensors, leading every day to the production of  masses of visual data. 
        In some contexts, these data can take the form of $2D$ images time series leading to $3D$ data that we note $2D+t$. 
        This type of data is frequent in several domains such as remote surveillance or remote sensing.   
        Because of their dimensions, the analysis and interpretation of this mass of data is a major challenge in computer vision. 
        This thesis is in the context of the exploitation of these data in order to classify them, by exploiting the maximum the wealth of spatial and temporal information carried by these data. 
        The research works presented in this manuscript includes two methods that proceed differently but whose common point is based on a change of the representation of the initial data. 
        The first method is based on the extraction of hand-crafted features while the second one is based on the use of machine learning methods, in particular deep convolutional neural networks. 
        Through these two methods, we propose to study the temporal stability of image times series  with hand-crafted features and to study their spatial and temporal variability with deep convolutional neural networks.  
        The two methods are then evaluated on two different applications. 
        One is related to satellite image time series and the other is related to surveillance camera videos. 
        The experimental results illustrate the interest of the proposed methods. 
        
        
       
    </div>


    



    <footer class="container">

      <p>&copy; Mohamed Chelali</p>
    </footer>


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <!--script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery-slim.min.js"><\/script>')</script-->
    <script src="js/vendor/popper.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script type="text/javascript"
  src="https://www.maths.nottingham.ac.uk/plp/pmadw/LaTeXMathML.js">
  </script>

  </body>
</html>
