<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <link rel="icon" href="image/favicon.png" />


    <meta name="description" content="Prise en compte de l'information spatiale et temporelle pour l'analyse de séquences d'images"/>
    <meta name="keywords" content="Mohamed CHELALI, neural networks, Ph.D., computer vision, artificial intelligence, image time series, séquences d'images, features extraction"/>
    <meta name="robots" content="index,follow"/>
    <meta name="author" content="Mohamed CHELALI" />
    <meta name="publisher" content="Mohamed CHELALI" />



    <meta property="og:title" content="Mohamed CHELALI, neural networks, Ph.D., computer vision, artificial intelligence, image time series, séquences d'images, features extraction" />
    <meta property="og:type" content="blog" />
    <meta property="og:url" content="image/favicon.png" />
    <meta property="og:image" content="image/favicon.png" />
    <meta property="og:site_name" content="mchelali.github.io" />
    <meta property="og:description" content="Prise en compte de l'information spatiale et temporelle pour l'analyse de séquences d'images" />


    <meta name="twitter:image" content="image/favicon.png">
    <meta name="twitter:image:alt" content="Ph.D. in image time series analysis of Mohamed CHELALI">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Ph.D. in image time series analysis of Mohamed CHELALI">
    <meta name="twitter:description" content="Prise en compte de l'information spatiale et temporelle pour l'analyse de séquences d'images">

    <meta name="twitter:domain" content="mchelali.github.io"/>
    <meta name="twitter:url" content="image/favicon.png"/>
    <meta name="twitter:site" content="@MedChelali" />
    <meta name="twitter:creator" content="@MedChelali" />

    <title>Mohamed Chelali</title>

    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/jumbotron.css" rel="stylesheet">
    <!--link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"-->


      <link rel="stylesheet" href="css/style.css">

    <!-- include font awosome package -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
    <link href="fontawesome-free-6.0.0-beta2-web/css/all.css" rel="stylesheet">
    <script defer src="fontawesome-free-6.0.0-beta2-web/js/all.min.js"></script>

  </head>

  <body>

      
    <div class="container" >

        

        <h5>
          Doctorat en informatique, spécialité image et vision
        </h5>
        
        <br>

        <h3>
          <center>
            Prise en compte de l'information spatiale et temporelle<br>pour l'analyse de séquences d'images 
          </center>
        </h3>
        <br>
        <!--h3>Thèse en informatique, spécialité analyse et traitement d'image</h3-->

        <br>
            <!--p>
              <i class="fas fa-calendar-alt"></i> <b>Vendredi 26 Novembre 2021, à 13h</b><br>
              <i class="fas fa-map-marked-alt"></i> <a href="https://www.google.com/maps/place/Universit%C3%A9+de+Paris+Campus+-+Saint-Germain-des-Pr%C3%A9s/@48.8553052,2.3308575,18z/data=!4m13!1m7!3m6!1s0x47e671d7c1c9c0df:0x731ec5500336bb89!2sUniversite+Paris+Descartes,+45+Rue+des+Saints-P%C3%A8res,+75006+Paris!3b1!8m2!3d48.8553052!4d2.3318301!3m4!1s0x47e671d7c324482b:0x5cd6e016f2621760!8m2!3d48.8560148!4d2.3316039" target="_blank">Université de Paris, 45 rue des Saints-Pères, Paris 75006</a><br>
              <i class="fas fa-subway"></i> Métro 4, Station: Saints Germains des Près <br>
              <i class="fa-solid fa-stairs"></i> <a href="image/acces.pdf">Accès à la salle</a>
            </p-->
            <p>
              Soutenue le 26 novembre 2021 au LIPADE à l'Université de Paris <br>
              Dirigée par <a href="https://helios2.mi.parisdescartes.fr/~vincent/siten/">Nicole Vincent</a> et <a href="https://camille-kurtz.com/">Camille Kurtz</a>

            </p>
        <br>
        
        <hr>
     
        <h1 class="display-5">Résumé </h1>
        <p class="text-justify"> 
          L'évolution de la technologie numérique a permis la multiplicité des capteurs d'images avec lesquels des masses de données visuelles sont quotidiennement produites. 
          Dans certains contextes, ces données peuvent prendre la forme de séquences temporelles d'images $2D$ conduisant à des données $3D$ que nous noterons $2D+t$. 
        Ce type de données est fréquent dans plusieurs domaines tels que la télésurveillance ou la télédétection. 
        De par leur dimension, l'analyse et l'interprétation de toute cette masse de données constitue un des défis importants en vision par ordinateur. 
        Cette thèse s'inscrit dans le contexte de l'exploitation de ces données afin de pouvoir les classifier, en exploitant au maximum la richesse des informations spatiales et temporelles portées par ces données.  
        Les travaux de recherche présentés dans ce manuscrit comprennent deux méthodes qui procèdent différemment mais dont le point commun repose sur un changement de représentation des données initiales. 
        La première méthode se base sur l'extraction de caractéristiques expertes  (<i>hand-crafted</i>) tandis que la deuxième concerne l'utilisation des méthodes d'apprentissage automatique, en particulier les réseaux de neurones convolutifs profonds. 
        À travers ces deux méthodes, nous nous proposons d'étudier la stabilité temporelle des séquences temporelles d'images avec les caractéristiques expertes et étudier leurs variabilités spatiale et temporelle avec les réseaux de neurones convolutifs profonds.  
        Les deux méthodes sont ensuite évaluées sur deux applications différentes. 
        Une de ses application concerne les séries temporelles d'images satellitaires et l'autre concerne les vidéos de caméra de surveillance. 
        Les résultats expérimentaux illustrent l’intérêt des méthodes proposées. 
        </p>
        
        
        
        
        

        <h1 class="display-5">Abstract </h1>
        
        <p class="text-justify"> 
          The evolution of digital technology has allowed the multiplicity of image sensors, leading every day to the production of  masses of visual data. 
          In some contexts, these data can take the form of $2D$ images time series leading to $3D$ data that we note $2D+t$. 
          This type of data is frequent in several domains such as remote surveillance or remote sensing.   
          Because of their dimensions, the analysis and interpretation of this mass of data is a major challenge in computer vision. 
          This thesis is in the context of the exploitation of these data in order to classify them, by exploiting the maximum the wealth of spatial and temporal information carried by these data. 
          The research works presented in this manuscript includes two methods that proceed differently but whose common point is based on a change of the representation of the initial data. 
          The first method is based on the extraction of hand-crafted features while the second one is based on the use of machine learning methods, in particular deep convolutional neural networks. 
          Through these two methods, we propose to study the temporal stability of image times series  with hand-crafted features and to study their spatial and temporal variability with deep convolutional neural networks.  
          The two methods are then evaluated on two different applications. 
          One is related to satellite image time series and the other is related to surveillance camera videos. 
          The experimental results illustrate the interest of the proposed methods. 
        </p>
        
        
        <h3>Liste des publication </h3>
       
    </div>


    



    <footer class="container">

      <p>&copy; Mohamed Chelali</p>
    </footer>


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <!--script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery-slim.min.js"><\/script>')</script-->
    <script src="js/vendor/popper.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script type="text/javascript"
  src="https://www.maths.nottingham.ac.uk/plp/pmadw/LaTeXMathML.js">
  </script>

  </body>
</html>
